!pip install lxml
!pip install wordcloud
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from bs4 import BeautifulSoup
import nltk
import string
nltk.download('omw-1.4')
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')


types = pd.read_csv("MBTI_type.csv")
posts = pd.read_csv("MBTI_posts.csv")

sep_posts = posts['posts'].str.split("\|\|\|", expand = True)
sample_posts = pd.DataFrame(sep_posts[0])

data = pd.concat([types, sample_posts], axis=1)
data.columns = ['type', 'posts']

    
group_data = data.groupby('type')

mbti_types = ['estj', 'entj', 'esfj', 'enfj', 
              'istj', 'isfj', 'intj', 'infj',
              'estp', 'entp', 'esfp', 'enfp', 
              'istp', 'intp', 'isfp', 'infp']

mbti=[]
for x in mbti_types:
    l = x.upper()
    mbti += [l]

# BAR CHART FOR 10 FREQUENTLY USED WORDS 

# Remove stopwords using the 'english' library which includes words such as (the, a, an, is, to)
stopwords = set(nltk.corpus.stopwords.words('english'))
stopwords = stopwords.union(set(string.punctuation))

# Remove Lemmatize words
wnl = nltk.WordNetLemmatizer()

# Defining a function that cleans, tokenizes, removes stopwords, and lemmatizes words in a text
def text_prep(txt):
    soup = BeautifulSoup(txt, "lxml")
    [s.extract() for s in soup('style')]
    txt=soup.text
    txt = txt.lower()
    tokens = [token for token in nltk.tokenize.word_tokenize(txt)]
    tokens = [token for token in tokens if not token in stopwords]
    tokens = [wnl.lemmatize(token) for token in tokens]
    if (len(tokens)==0):
        tokens = ["EMPTYSTRING"]
    return(tokens)

# Transforming a groupby object for ENTJ personality type to a list of words in order to use the FreqDist command
ENTJ = pd.Series(' '.join(group_data['posts'].get_group('ENTJ')).lower().split()).to_string(index = False)
ENTJ = text_prep(ENTJ)


# WORDCLOUD CONSISTING OF 10 FREQUENTLY USED WORDS - Individual code
#ENTJ_str = ' '.join(ENTJ)
#wordcloud_ENTJ = WordCloud(collocations = False, background_color = 'white').generate(ENTJ_str)
#plt.imshow(wordcloud_ENTJ, interpolation='bilinear')
#plt.axis("off")
#plt.show()


# BAR CHARTS SHOWING 10 FREQUENTLY USED WORDS BY EACH PERSONALITY TYPE - Individual code
#post_dict = wordcloud_ENTJ.process_text(ENTJ_str)
#word_freq={k: v for k, v in sorted(post_dict.items(),reverse=True, key=lambda item: item[1])}
#dist = pd.DataFrame(list(word_freq.items())[:10])
#dist.columns = ["Words", "Count"]
#dist.plot.bar(x='Words', y='Count', figsize=(12,4))

# To make a for loop that iterates over each persoanlity type and create a list of words
i=0
while i < 16:
    for t in mbti:
        group = pd.Series(' '.join(group_data['posts'].get_group(f"{t}")).lower().split()).to_string(index = False)
        group = text_prep(group)
        group_str = ' '.join(group)
        wordcloud = WordCloud(collocations = False, background_color = 'white').generate(group_str)
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")
        plt.tight_layout()
        plt.show()
        post_dict = wordcloud.process_text(group_str)
        word_freq={k: v for k, v in sorted(post_dict.items(),reverse=True, key=lambda item: item[1])}
        dist = pd.DataFrame(list(word_freq.items())[:10])
        dist.columns = ["Words", "Count"]
        plt.subplots_adjust(hspace=0.5,  wspace=0.5)
        i+=1
